{
	"data": {
		"filename": "dataset\\Feature_engineering_20190624_083438.csv",
		"columns": [
			"daily_close", 
			"daily_vol"
		],
		"sequence_length": 50,
		"train_test_split": 0.9,
		"normalise": true
	},
	"training": {
		"epochs": 5,
		"batch_size": 32
	},
	"model": {
		"_comment":"模型结构：input -> LSTM -> dropout -> LSTM -> LSTM -> dropout -> dense -> output 使用平方误差loss",
		"loss": "mse",
		"optimizer": "adam",
		"save_dir": "saved_models",
		"layers": [
			{
				"type": "lstm",
				"neurons": 256,
				"input_timesteps": 50,
				"input_dim": 488,
				"return_seq": true,
				"_comment":"LSTM层，输入是2维的49个时间步的序列数据，神经维度为100，输出整个序列"
			},
			{
				"type": "dropout",
				"rate": 0.2,
				"_comment":"dropout比例为0.2，很奇怪本身LSTM就自带dropout方法，直接用不就行了"
			},
			{
				"type": "lstm",
				"neurons": 256,
				"return_seq": true,
				"_comment":"LSTM层，输入是上一个LSTM cell的输出 100维的50个时间步的序列数据，神经维度为100，输出整个序列"
			},
			{
				"type": "lstm",
				"neurons": 100,
				"return_seq": true,
				"_comment":"LSTM层，输入是上一个LSTM cell的输出 100维的49个时间步的序列数据，神经维度为100，只输出最后一个结果"
			},
			{
				"type": "dropout",
				"rate": 0.2
			},
			{
				"type": "flatten"
			},
			{
				"type": "dense",
				"neurons": 50,
				"activation": "linear",
				"_comment":"Dence层，输入是上一个LSTM cell的输出 100维的1个时间步，输出神经维度为1，是最后的标签数据"
			}
		]
	}
}
